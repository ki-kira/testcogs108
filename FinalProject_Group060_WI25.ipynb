{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 108 - Final Project (change this to your project's title)\n",
    "\n",
    "# Permissions\n",
    "\n",
    "Place an `X` in the appropriate bracket below to specify if you would like your group's project to be made available to the public. (Note that student names will be included (but PIDs will be scraped from any groups who include their PIDs).\n",
    "\n",
    "* [  ] YES - make available\n",
    "* [  ] NO - keep private\n",
    "\n",
    "# Names\n",
    "\n",
    "- Dhanashree Kulkarni\n",
    "- Neela Kolte\n",
    "- Krystal Chai\n",
    "- Kira Nguyen\n",
    "- Curtis Chen\n",
    "\n",
    "# Abstract\n",
    "\n",
    "Please write one to four paragraphs that describe a very brief overview of why you did this, how you did, and the major findings and conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Research Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-  Include a specific, clear data science question.\n",
    "-  Make sure what you're measuring (variables) to answer the question is clear\n",
    "\n",
    "What is your research question? Include the specific question you're setting out to answer. This question should be specific, answerable with data, and clear. A general question with specific subquestions is permitted. (1-2 sentences)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background and Prior Work"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The Oscars is an awards ceremony meant to honor notable films in 24 respective categories, some of which include: Best Supporting Actress, Best Visual Effects, Best Director, and the like. Those who are nominated in each category are determined by the Academy, a group of individuals deemed to be dominated by white people (reported 19% nonwhite in 2022). Since Academy members also determine the winners, much controversy has erupted surrounding the lack of diversity and prejudiced nominations. \n",
    "\n",
    "The Oscars has historically been accused of being racist and sexist, and often not representing the opinion of viewer populations. Nominations of non-white artists are still much lesser, and there continues to be a lack of representation in the winners of the awards. From 1989 to 2015, 98.9% of winners for the Best Actress award were white artists, and similarly 93.2% of winners for the Best Actor award were white.<a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1) From the beginning of the Academy Awards in 1929, only about 17% of the nominees have been women. The Oscars have claimed to take big steps to combat racism and bias in the proceedings of the awards but efforts to combat sexism are much less profound.\n",
    "\n",
    "Nonetheless, the improvements, a panicked response to the public retaliating against this inequity in 2015 with the trending hashtag #OscarsSoWhite, doubled women and tripled their members of color on the Academy board.<a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2) The overall nomination for underrepresented communities has also increased from about 9.5% to 17% since the hashtag made its rounds.<a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3) However, The Inclusion List, a prior and continuing work focusing on data analysis in the entertainment industry to promote inclusivity, corroborates the need for even greater initiatives. Though their analysis, sorted into gender and ethnicity and broken down in every single award category, shows an overall uptick, their visualizations often highlight the remaining inequality (ex. Pie chart with text, “<2% of nominees for Best Director were women”).<a name=\"cite_ref-4\"></a>[<sup>4</sup>](#cite_note-4) Our project covers a similar domain (more narrow in range), but aims to contextualize the analysis through recent trends in film and further demographic information if possible.\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Chen, S. (13 May 2022) The Discriminatory Bias of Award Shows. *The Spectator*. https://stuyspec.com/article/the-discriminatory-bias-of-award-shows \n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Latif, L. (14 April 2021) Has the Oscars really faced up to its race problem? *BBC*. https://www.bbc.com/culture/article/20210414-has-the-oscars-really-fixed-its-race-problem \n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) Smith, S. (2025) Oscars So White *The Inclusion List*. https://www.inclusionlist.org/oscars/oscars-so-white \n",
    "4. <a name=\"cite_note-4\"></a> [^](#cite_ref-4) Smith, S. (2025) Best Director *The Inclusion List*. https://www.inclusionlist.org/oscars/director \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We hypothesize that an academy award nominee’s intersectionality of race and gender will negatively affect their likelihood of winning (win rate) if they are not white and/ or male. We control for the type of film by 1) mainly focusing on categories that do not take film type into account, and 2) aggregating all types of films for writing categories. We intend to test for statistical evidence of disparity between race and gender specifically that will overall hinder the nominees’ likelihood of winning.\n",
    "Additionally, We also want to include birthplace as a proxy to industry connection as a variable to find a positive correlation between industry connection and nomination rate in order to further expand on prior work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data overview\n",
    "\n",
    "For each dataset include the following information\n",
    "- Dataset #1\n",
    "  - Denoted as oscars_data.csv in the repo.\n",
    "  - Dataset Name: Academy awards dataset (oscars)\n",
    "  - Link to the dataset: https://www.kaggle.com/datasets/dharmikdonga/academy-awards-dataset-oscars%20/data\n",
    "  - Number of observations: 10396\n",
    "  - Number of variables: 9\n",
    "- Dataset #2 (if you have more than one!)\n",
    "  - Denoted as birthplace_data.csv in the repo.\n",
    "  - Dataset Name: Oscars - Best Actors and Actresses\n",
    "  - Link to the dataset: http://jse.amstat.org/datasets/oscars.dat.txt\n",
    "  - Number of observations: 155\n",
    "  - Number of variables: 3\n",
    "\n",
    "Dataset #1 was configured in reference to another kaggle dataset, https://www.kaggle.com/datasets/unanimad/the-oscar-award/data, but expands on it by adding columns on race and gender. It contains information on the gender, race, category, ceremony number and year for all Oscar winners and nominees from 1927-2019. It also includes the film name and year the film was made. The variables in the dataset are of object (string), Boolean, and integer type. The wrangling process for this dataset included: extracting only values that applied to our research, excluding columns we did not need (film title and film year), and standardizing unique values to certain categories as we see fit. After cleaning the .csv file, we did not find any null values.\n",
    "Dataset #2 was curated by the Journal of Statistical Education. It has data on the winners of the Best Actor and Best Actress awards from 1929 to 2005, and details about their birthplace, year of birth, brith month, birth day, and the age at which they won the Oscar. For our purposes we extracted only the columns for the name of the actor/actress, their gender, the number of the ceremony in which they won, and their birthplace. Birthplace is defined as the U.S. state of birth for those born in the U.S. or the country of birth for those born elsewhere. All the variables in this dataset are of object (string) data type. The wrangling process for this dataset included filtering the relevant columns and dropping the rest. There is no missing data but it covers only a subset of the years covered in the first dataset.\n",
    "\n"
   ]
  },
   {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWbrjQ2DIXdf",
        "outputId": "05183950-db62-4bbe-c0ac-0ca664f0af6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   year_film  year_ceremony  ceremony      Category  gender           name  \\\n",
            "0       1927           1928         1    Best Actor    Male  Emil Jannings   \n",
            "1       1927           1928         1  Best Actress  Female   Janet Gaynor   \n",
            "2       1928           1929         2    Best Actor    Male  Warner Baxter   \n",
            "3       1928           1929         2  Best Actress  Female  Mary Pickford   \n",
            "4       1929           1930         3    Best Actor    Male  George Arliss   \n",
            "\n",
            "    Race              film  winner  \n",
            "0  White  The Last Command    True  \n",
            "1  White        7th Heaven    True  \n",
            "2  White    In Old Arizona    True  \n",
            "3  White          Coquette    True  \n",
            "4  White          Disraeli    True  \n",
            "Shape of data1:  (10396, 9)\n"
          ]
        }
      ],
      "source": [
        "data1 = pd.read_csv('oscars_data.csv')\n",
        "print(data1.head())\n",
        "print('Shape of data1: ', data1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9S9zltnIZke",
        "outputId": "c91729ca-a852-401c-ccec-13531f9a716a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   Year_ceremony  Ceremony      Category  Gender           Name   Race  Winner\n",
            "0           1928         1    Best Actor    Male  Emil Jannings  White    True\n",
            "1           1928         1  Best Actress  Female   Janet Gaynor  White    True\n",
            "2           1929         2    Best Actor    Male  Warner Baxter  White    True\n",
            "3           1929         2  Best Actress  Female  Mary Pickford  White    True\n",
            "4           1930         3    Best Actor    Male  George Arliss  White    True\n",
            "Revised shape of data1:  (2339, 7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-132-2d9e5be3afb6>:4: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data1.drop('film', axis=1, inplace=True)\n",
            "<ipython-input-132-2d9e5be3afb6>:5: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  data1.drop('year_film', axis=1, inplace=True)\n"
          ]
        }
      ],
      "source": [
        "# Extracting values that we want to focus on in our project.\n",
        "data1 = data1[data1['Category'].isin(['Best Actor', 'Best Actress', 'DIRECTING (Comedy Picture)','DIRECTING (Dramatic Picture)', 'DIRECTING', 'WRITING (Adapted Screenplay)', 'WRITING (Original Story)','WRITING (Title Writing)', 'WRITING (Original Screenplay)', 'WRITING (Original Motion Picture Story)','WRITING (Motion Picture Story)', 'WRITING (Story and Screenplay)', 'WRITING (Screenplay--Original)', 'WRITING (Story and Screenplay--written directly for the screen)', 'WRITING (Story and Screenplay--based on material not previously published or produced)', 'WRITING (Story and Screenplay--based on factual material or material not previously published or produced)','WRITING (Screenplay Written Directly for the Screen--based on factual material or on story material not previously published or produced)','WRITING (Screenplay Written Directly for the Screen)'])]\n",
        "# Dropping the columns that we are not using in our analysis.\n",
        "data1.drop('film', axis=1, inplace=True)\n",
        "data1.drop('year_film', axis=1, inplace=True)\n",
        "# Naming the columns of data1.\n",
        "data1.columns = ['Year_ceremony', 'Ceremony', 'Category', 'Gender', 'Name', 'Race','Winner']\n",
        "print(data1.head())\n",
        "print('Revised shape of data1: ', data1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Ugy3FKdIcDC",
        "outputId": "2a5e2a4e-8489-4730-ff6e-9490e0b7db64"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Best Actor',\n",
              " 'Best Actress',\n",
              " 'DIRECTING (Comedy Picture)',\n",
              " 'DIRECTING (Dramatic Picture)',\n",
              " 'WRITING (Adapted Screenplay)',\n",
              " 'WRITING (Original Story)',\n",
              " 'WRITING (Title Writing)',\n",
              " 'DIRECTING',\n",
              " 'WRITING (Original Screenplay)',\n",
              " 'WRITING (Original Motion Picture Story)',\n",
              " 'WRITING (Motion Picture Story)',\n",
              " 'WRITING (Story and Screenplay)',\n",
              " 'WRITING (Screenplay--Original)',\n",
              " 'WRITING (Story and Screenplay--written directly for the screen)',\n",
              " 'WRITING (Story and Screenplay--based on material not previously published or produced)',\n",
              " 'WRITING (Story and Screenplay--based on factual material or material not previously published or produced)',\n",
              " 'WRITING (Screenplay Written Directly for the Screen--based on factual material or on story material not previously published or produced)',\n",
              " 'WRITING (Screenplay Written Directly for the Screen)']"
            ]
          },
          "metadata": {},
          "execution_count": 133
        }
      ],
      "source": [
        "# Seeing if all values of our revised DataFrame are applicable to our subsequent function.\n",
        "list(data1['Category'].unique())"
      ]
    },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function that performs simple substring checking to group repeating unique values together.\n",
    "def standardize_categories(category):\n",
    "# Converting all text to lowercase and using strip() to remove leading and trailing characters.\n",
    "  category = category.strip().lower()\n",
    "  if 'actor' in category:\n",
    "    category = 'Best Actor'\n",
    "  elif 'actress' in category:\n",
    "    category = 'Best Actress'\n",
    "  elif 'directing' in category:\n",
    "    category = 'Best Director'\n",
    "  elif 'writing' in category:\n",
    "    category = 'Best Screenplay'\n",
    "  else:\n",
    "    return None\n",
    "  category = category.strip()\n",
    "  return category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the transformation to our revised dataset.\n",
    "data1['Category'] = data1['Category'].apply(standardize_categories)\n",
    "# Verifying that the function works and is applied to our new dataset.\n",
    "list(data1['Category'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing data.\n",
    "data1.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data1['Race'].value_counts())\n",
    "print(data1['Gender'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the distribution of race entries in our dataset.\n",
    "sns.countplot(x = data1['Race'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the distribution of male and female entries in our dataset.\n",
    "sns.countplot(x = data1['Gender'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset #2 (birthplace_data.csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = pd.read_csv('birthplace_data.csv')\n",
    "# Naming the columns of data2.\n",
    "data2.columns = ['Gender','Ceremony','Year_of_award','Name','Film','Age_when_won','State/Country','Birth_month','Birth_day','Birth_year']\n",
    "# Dropping the columns that we are not using in our analysis.\n",
    "data2.drop(['Year_of_award','Film','Age_when_won','Birth_month','Birth_day','Birth_year'], axis=1, inplace=True)\n",
    "print(data2.head())\n",
    "print('Shape of data2: ', data2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for missing data.\n",
    "print(data2.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the distribution of male and female entries in our dataset.\n",
    "print(data2['Gender'].value_counts())\n",
    "sns.countplot(x = data2['Gender'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "## Exploratory Data Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Trends in Oscar Winners by Race and Gender Over Time\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## YOUR CODE HERE\n",
    "## FEEL FREE TO ADD MULTIPLE CELLS PER SECTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inferential Statistics \n",
    "\n" 
   ]
  },
  {
    "cell_type": "code",
    "execution_count": null,
    "metadata": {},
    "outputs": [],
    "source": [
     "# Replacing True and False values with 1s and 0s.\n", 
     "data1 = data1.replace({True: 1, False: 0})"
    ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a logistic regression statistics model.\n",
    "mod = smf.logit('Winner ~ C(Gender, Treatment(reference=\"Male\")) + C(Race, Treatment(reference=\"White\")) + C(Category) + Year_ceremony', data1).fit()\n",
    "print(mod.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictive Model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS IS THE PREPROCESSING FOR THE MODEL.\n",
    "# Defining the predictors and target variables.\n",
    "X = data1[['Category', 'Race', 'Gender', 'Year_ceremony']]\n",
    "y= data1['Winner']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding the categorical independent variables using the OneHotEncoder.\n",
    "encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "X_encoded = encoder.fit_transform(X[['Race', 'Gender', 'Category']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a new dataframe from the encoded values.\n",
    "X_encoded_df = pd.DataFrame(X_encoded, columns=encoder.get_feature_names_out(['Race', 'Gender', 'Category']))\n",
    "X_encoded_df.reset_index(drop=True)\n",
    "# Adding the Year_ceremony values to the independent variables.\n",
    "new_column = list(X['Year_ceremony'])\n",
    "X_encoded_df['Year_ceremony'] = new_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting data into training and test data and shuffling.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded_df, y, test_size=0.5, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling the Year_ceremony column using StandardScaler.\n",
    "sc = StandardScaler()\n",
    "X_train['Year_ceremony'] = sc.fit_transform(np.array(X_train['Year_ceremony']).reshape(-1, 1))\n",
    "X_test['Year_ceremony'] = sc.fit_transform(np.array(X_test['Year_ceremony']).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Random Forest Classifier based on n_estimators that we determined through cross-validation scores.\n",
    "rf = RandomForestClassifier(n_estimators=9, random_state=0)\n",
    "rf.fit(X_train, y_train)\n",
    "# Making predictions, and printing the classification report and confusion matrix.\n",
    "y_pred = rf.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ethics & Privacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Thoughtful discussion of ethical concerns included\n",
    "- Ethical concerns consider the whole data science process (question asked, data collected, data being used, the bias in data, analysis, post-analysis, etc.)\n",
    "- How your group handled bias/ethical concerns clearly described\n",
    "\n",
    "Acknowledge and address any ethics & privacy related issues of your question(s), proposed dataset(s), and/or analyses. Use the information provided in lecture to guide your group discussion and thinking. If you need further guidance, check out [Deon's Ethics Checklist](http://deon.drivendata.org/#data-science-ethics-checklist). In particular:\n",
    "\n",
    "- Are there any biases/privacy/terms of use issues with the data you propsed?\n",
    "- Are there potential biases in your dataset(s), in terms of who it composes, and how it was collected, that may be problematic in terms of it allowing for equitable analysis? (For example, does your data exclude particular populations, or is it likely to reflect particular human biases in a way that could be a problem?)\n",
    "- How will you set out to detect these specific biases before, during, and after/when communicating your analysis?\n",
    "- Are there any other issues related to your topic area, data, and/or analyses that are potentially problematic in terms of data privacy and equitable impact?\n",
    "- How will you handle issues you identified?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discusison and Conclusion\n",
    "\n",
    "Wrap it all up here.  Somewhere between 3 and 10 paragraphs roughly.  A good time to refer back to your Background section and review how this work extended the previous stuff. \n",
    "\n",
    "\n",
    "# Team Contributions\n",
    "\n",
    "Speficy who did what.  This should be pretty granular, perhaps bullet points, no more than a few sentences per person."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
